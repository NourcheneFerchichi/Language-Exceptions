{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SightengineNLP-TechnicalAssignment-NourcheneFerchichi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1.\n",
        "What approach would you use to automatically determine what languages are used in a given message? Please keep in mind that messages do not always contain two different languages, they can also contain just one language. If you believe that some situations cannot be handled by your implementation, please specify which ones and why."
      ],
      "metadata": {
        "id": "9S5m4deiQ3Lz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xrGQ3E_Qsxr",
        "outputId": "2cc3cb9f-33bb-4de9-f1c3-4b35a36b9f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 24.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=89f2f7d64c58624384c981a6227f2c290de4ace74217f761e5f97b8a1be9558d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from langdetect import detect, detect_langs\n",
        "from typing import List\n",
        "\n",
        "class Solution():\n",
        "  \"\"\"\n",
        "  Detect languages in a text message, in a context where users often write \n",
        "  messages containing multiple languages.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, words_to_combine: int, message: str, max_lang: int):\n",
        "    \"\"\" Class initialiser\n",
        "    \n",
        "    Args:\n",
        "        words_to_combine (int): The number N of N-grams.\n",
        "        message (str): The user's multilangual text message.\n",
        "        max_lang (int): The maximun number of languages to be detected.\n",
        "    \"\"\"\n",
        "    self.words_to_combine = words_to_combine\n",
        "    self.message = message\n",
        "    self.max_lang = max_lang\n",
        "\n",
        "  def generate_ngrams(self) -> List[str]:\n",
        "      \"\"\" Creates an N-grams of all possible combinations of “N” successive\n",
        "      words from a text.\n",
        "      \n",
        "      Returns:\n",
        "          output (List[str]): The list of the generated N-grams. \n",
        "      \"\"\"\n",
        "      words = self.message.split()\n",
        "      output = []  \n",
        "      for i in range(len(words)-self.words_to_combine+1):\n",
        "          output.append(\" \".join(words[i:i+self.words_to_combine-1]))\n",
        "      return output\n",
        "\n",
        "  def detect_languages(self):\n",
        "    \"\"\"Detect the language of a text message. \n",
        "    \n",
        "    Returns:\n",
        "        detected_languages (dict): The dictionary of detected languages.\n",
        "                detected_languages[n_gram_text] = language\n",
        "        n (int): The number on generated N-grams.\n",
        "    \"\"\"\n",
        "    detected_languages = {}\n",
        "    n_grams = self.generate_ngrams()\n",
        "    for sub_set in n_grams:\n",
        "        detected_languages[sub_set] = detect(sub_set)\n",
        "    return detected_languages, len(n_grams)\n",
        "    \n",
        "  def get_top_languages(self) -> None:\n",
        "      \"\"\"Extract the top self.max_lang languages\n",
        "      \"\"\"\n",
        "      detected_languages, total_grams = self.detect_languages()\n",
        "      count = Counter(detected_languages.values())\n",
        "      sorted_count = sorted(\n",
        "          dict(count).items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "      if sorted_count[0][1]/total_grams >= 0.80: # Only one Language is present\n",
        "        detected_languages = sorted_count[0]\n",
        "        print(f\"The detected language in: '%s' is: %s\" %(self.message, detected_languages[0][0].upper()))\n",
        "      else:\n",
        "        detected_languages = sorted_count[:self.max_lang] # Multiple languages are present\n",
        "        print(f\"The detected languages in: '%s' are: %s and %s\" %(self.message, detected_languages[0][0].upper(), detected_languages[1][0].upper()))\n",
        "\n",
        "### Test Solution ###\n",
        "document = [\"Hello, tu as vu Lost in the Middle of Night l’autre jour ?\",\n",
        "        \"This is an English sentence written in english, dans un endroit frais et sec\",\n",
        "        \"Who are you? 小家伙 or just what we call 非常小的家伙\",\n",
        "        \"توفر Analytics Vidhya بوابة معرفية قائمة على المجتمع لمحترفي التحليلات وعلوم البيانات\",\n",
        "        \"Hello, how are you doing?\"]\n",
        "\n",
        "solution = Solution(words_to_combine=3, message=document[1], max_lang=2)\n",
        "solution.get_top_languages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhcCslCmQ6Xp",
        "outputId": "6e7cb63b-af79-4819-9fc1-9c201140c9cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The detected languages in: 'This is an English sentence written in english, dans un endroit frais et sec' are: EN and FR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2.\n",
        "How would you proceed to detect if a given word is a variation of the word “blackhat”? Please write a Python function that determines if a string is a variation of this word. How would you generalize this to any given term?"
      ],
      "metadata": {
        "id": "BGBnJePMQ-1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates(word: str) -> str:\n",
        "    \"\"\" Delete duplicates characters from a string\n",
        "        \n",
        "    Args:\n",
        "        word (str): A word with duplicated characters.\n",
        "\n",
        "    Returns:\n",
        "      Output (str): The word after deleting its duplicated characters.\n",
        "    \"\"\"\n",
        "    chars = []\n",
        "    prev = \"\"\n",
        "    for char in word:\n",
        "        if prev != char:\n",
        "            chars.append(char)\n",
        "            prev = char\n",
        "    output = ''.join(chars)\n",
        "    return output\n",
        "\n",
        "def check_obfuscation(original_word: str, variation_word: str) -> bool:\n",
        "    \"\"\" Verifies if an is variation_word the variation of the original_word\n",
        "\n",
        "    Args:\n",
        "        original_word (str): An original word.\n",
        "        variation_word (str): A possible obfuscation of the original one.\n",
        "\n",
        "    Returns:\n",
        "      same_word (bool): True if original_word and variation_word are similar,\n",
        "      False else.\n",
        "    \"\"\"\n",
        "    same_word = False\n",
        "    variation_word = variation_word.replace(\"@\", \"a\")\n",
        "    new_word = \"\".join(char for char in variation_word if char.isalpha())\n",
        "    new_word = remove_duplicates(new_word)\n",
        "    if original_word == new_word:\n",
        "        same_word = True\n",
        "    return same_word\n",
        "\n",
        "\n",
        "### Test Solution ###\n",
        "words = [\"blackkkhat\", \"bl@khat\", \"b__la-c_k_hat\", \"abcd\"]\n",
        "check_obfuscation(original_word=\"blackhat\", variation_word=words[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6raSogsQ_x8",
        "outputId": "cfc6870b-4845-49af-ec22-a766942be2e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NiEEYVO0RF4E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}